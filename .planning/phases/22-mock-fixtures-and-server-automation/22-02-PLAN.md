---
phase: 22-mock-fixtures-and-server-automation
plan: 02
type: execute
wave: 2
depends_on: ["22-01"]
files_modified:
  - ui/scripts/start-ui-server.ts
  - ui/scripts/start-inspect-server.ts
autonomous: true
requirements: [CAPT-02]

must_haves:
  truths:
    - "A script starts the rsf ui server for a given example, confirms it is ready via HTTP health check, and stops it cleanly"
    - "A script starts the mock inspect server with fixture data for a given example, confirms it is ready, and stops it cleanly"
    - "Both scripts accept an example name argument and a port argument"
    - "Both scripts output a clear ready message that downstream scripts can detect"
  artifacts:
    - path: "ui/scripts/start-ui-server.ts"
      provides: "Graph editor server lifecycle management"
      min_lines: 40
    - path: "ui/scripts/start-inspect-server.ts"
      provides: "Mock inspect server lifecycle management"
      min_lines: 40
  key_links:
    - from: "ui/scripts/start-ui-server.ts"
      to: "rsf ui"
      via: "child_process.spawn('python', ['-m', 'rsf', 'ui', ...])"
      pattern: "spawn.*rsf.*ui"
    - from: "ui/scripts/start-inspect-server.ts"
      to: "ui/scripts/mock-inspect-server.ts"
      via: "child_process.spawn('node', ['--import', 'tsx/esm', 'scripts/mock-inspect-server.ts', ...])"
      pattern: "spawn.*mock-inspect-server"
    - from: "ui/scripts/start-ui-server.ts"
      to: "HTTP health check"
      via: "fetch loop polling server until 200 response"
      pattern: "fetch.*127\\.0\\.0\\.1"
    - from: "ui/scripts/start-inspect-server.ts"
      to: "HTTP health check"
      via: "fetch loop polling /api/inspect/executions until 200 response"
      pattern: "fetch.*api/inspect/executions"
---

<objective>
Create server lifecycle management scripts that start, health-check, and stop both the graph editor (rsf ui) and mock inspect servers for any of the 5 example workflows.

Purpose: Phase 23 screenshot scripts need to programmatically launch servers, wait for readiness, take screenshots, and shut down cleanly. These scripts provide that foundation.
Output: 2 TypeScript scripts in ui/scripts/ — one for the graph editor server, one for the mock inspect server.
</objective>

<execution_context>
@/home/esa/.claude/get-shit-done/workflows/execute-plan.md
@/home/esa/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-mock-fixtures-and-server-automation/22-01-SUMMARY.md

Key files to reference:
@src/rsf/cli/ui_cmd.py
@src/rsf/editor/server.py
@ui/scripts/mock-inspect-server.ts
@ui/tsconfig.scripts.json

<interfaces>
<!-- Key contracts the executor needs. -->

From src/rsf/cli/ui_cmd.py (how rsf ui is launched):
```python
# CLI: rsf ui <workflow> --port <port> --no-browser
# Launches FastAPI on http://127.0.0.1:{port}
# Serves React SPA at / and WebSocket at /ws
# workflow arg is path to workflow.yaml
```

From ui/scripts/mock-inspect-server.ts (created in Plan 01):
```typescript
// CLI: node --import tsx/esm scripts/mock-inspect-server.ts --fixture <example-name> --port <port>
// Serves mock data on http://127.0.0.1:{port}
// GET /api/inspect/executions returns 200 when ready
// Outputs: "Mock inspect server started on port {port} (fixture: {example})"
```

From Phase 21 patterns:
```
// Scripts run via: node --import tsx/esm scripts/{script-name}.ts
// Scripts use tsconfig.scripts.json (moduleResolution: node)
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create start-ui-server.ts — graph editor server lifecycle script</name>
  <files>ui/scripts/start-ui-server.ts</files>
  <action>
Create `ui/scripts/start-ui-server.ts` that manages the graph editor server lifecycle for a given example workflow.

**CLI interface:**
```
node --import tsx/esm scripts/start-ui-server.ts --example order-processing --port 8765
```

**Arguments:**
- `--example <name>` (required) — One of: order-processing, approval-workflow, data-pipeline, retry-and-recovery, intrinsic-showcase
- `--port <number>` (optional, default 8765)

**Behavior:**
1. Parse CLI args (use simple process.argv parsing — no external dependencies)
2. Resolve the workflow path: `../examples/{example}/workflow.yaml` (relative to repo root, from ui/ directory the path is `../examples/{example}/workflow.yaml`)
3. Verify the workflow file exists, exit 1 with error if not
4. Spawn `rsf ui {workflow_path} --port {port} --no-browser` as a child process using `child_process.spawn('python', ['-m', 'rsf', 'ui', workflowPath, '--port', String(port), '--no-browser'])`
5. Pipe child stdout/stderr to console for debugging (prefix with `[rsf-ui]`)
6. Poll `http://127.0.0.1:{port}/` with fetch every 500ms until a 200 response (max 30 retries = 15 seconds timeout)
7. On ready: print `SERVER_READY: http://127.0.0.1:{port}` to stdout (this exact string is used by Phase 23 scripts to detect readiness)
8. Then wait — keep the process alive until SIGINT/SIGTERM
9. On shutdown signal: kill child process with SIGTERM, wait 2 seconds, if still alive send SIGKILL, then exit 0
10. Print `SERVER_STOPPED` on clean shutdown

**Error handling:**
- If health check times out (30 retries): kill child process, print error, exit 1
- If child process exits unexpectedly: print error with exit code, exit 1
- If workflow file not found: print error with path, exit 1

**Important:** Use `import { spawn } from 'node:child_process'`, `import { existsSync } from 'node:fs'`, `import { resolve } from 'node:path'`. The Python `rsf` module must be importable (it's installed in the local Python environment). The script runs from the `ui/` directory context.
  </action>
  <verify>
    <automated>cd /home/esa/git/rsf-python/ui && timeout 20 bash -c '
node --import tsx/esm scripts/start-ui-server.ts --example order-processing --port 18765 &
PID=$!
# Wait for SERVER_READY message (up to 15s)
for i in $(seq 1 30); do
  sleep 0.5
  RESP=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:18765/ 2>/dev/null || echo "000")
  if [ "$RESP" = "200" ]; then
    echo "UI server is ready (HTTP 200)"
    break
  fi
done
# Verify WebSocket endpoint exists
WS_RESP=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:18765/api/schema 2>/dev/null || echo "000")
echo "Schema endpoint: $WS_RESP"
kill $PID 2>/dev/null
wait $PID 2>/dev/null
echo "start-ui-server test PASSED"
' 2>&1</automated>
  </verify>
  <done>start-ui-server.ts spawns the rsf ui Python process for a given example, health-checks until ready, prints SERVER_READY on success, and shuts down cleanly on SIGINT/SIGTERM. The script is usable by Phase 23's screenshot capture scripts as a server lifecycle manager.</done>
</task>

<task type="auto">
  <name>Task 2: Create start-inspect-server.ts — mock inspect server lifecycle script</name>
  <files>ui/scripts/start-inspect-server.ts</files>
  <action>
Create `ui/scripts/start-inspect-server.ts` that manages the mock inspect server lifecycle for a given example workflow.

**CLI interface:**
```
node --import tsx/esm scripts/start-inspect-server.ts --example order-processing --port 8766
```

**Arguments:**
- `--example <name>` (required) — One of: order-processing, approval-workflow, data-pipeline, retry-and-recovery, intrinsic-showcase
- `--port <number>` (optional, default 8766)

**Behavior:**
1. Parse CLI args (simple process.argv parsing — no external dependencies)
2. Verify the fixture file exists at `scripts/fixtures/{example}.json`, exit 1 with error if not
3. Spawn `node --import tsx/esm scripts/mock-inspect-server.ts --fixture {example} --port {port}` as a child process
4. Pipe child stdout/stderr to console (prefix with `[mock-inspect]`)
5. Poll `http://127.0.0.1:{port}/api/inspect/executions` with fetch every 500ms until 200 response (max 20 retries = 10 seconds timeout)
6. On ready: print `SERVER_READY: http://127.0.0.1:{port}` to stdout
7. Wait — keep the process alive until SIGINT/SIGTERM
8. On shutdown signal: kill child process, exit 0
9. Print `SERVER_STOPPED` on clean shutdown

**Error handling:**
- Same patterns as start-ui-server.ts: timeout → kill + exit 1, unexpected exit → error + exit 1, file not found → error + exit 1

**Important:** This script spawns mock-inspect-server.ts (from Plan 01) as a child process, NOT the real Python inspect server. The mock server has no AWS dependency.

The script structure should be nearly identical to start-ui-server.ts — factor the common health-check polling loop into a helper function at the top of each file (or just duplicate the pattern; 2 files is fine). Do NOT create a shared module — keep each script self-contained for simplicity.
  </action>
  <verify>
    <automated>cd /home/esa/git/rsf-python/ui && timeout 15 bash -c '
node --import tsx/esm scripts/start-inspect-server.ts --example order-processing --port 18766 &
PID=$!
# Wait for SERVER_READY
for i in $(seq 1 20); do
  sleep 0.5
  RESP=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:18766/api/inspect/executions 2>/dev/null || echo "000")
  if [ "$RESP" = "200" ]; then
    echo "Mock inspect server is ready (HTTP 200)"
    break
  fi
done
# Verify execution detail endpoint
EXEC_ID=$(curl -s http://127.0.0.1:18766/api/inspect/executions | node -e "process.stdin.setEncoding(\"utf8\"); let d=\"\"; process.stdin.on(\"data\",c=>d+=c); process.stdin.on(\"end\",()=>console.log(JSON.parse(d).executions[0].execution_id))")
DETAIL_RESP=$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:18766/api/inspect/execution/$EXEC_ID 2>/dev/null || echo "000")
echo "Detail endpoint: $DETAIL_RESP"
kill $PID 2>/dev/null
wait $PID 2>/dev/null
echo "start-inspect-server test PASSED"
' 2>&1</automated>
  </verify>
  <done>start-inspect-server.ts spawns the mock-inspect-server.ts for a given example, health-checks until the /api/inspect/executions endpoint responds 200, prints SERVER_READY, and shuts down cleanly. The script is usable by Phase 23's screenshot capture scripts as the inspect server lifecycle manager.</done>
</task>

</tasks>

<verification>
1. start-ui-server.ts launches rsf ui for order-processing, returns HTTP 200 on the root URL
2. start-inspect-server.ts launches mock inspect server for order-processing, returns HTTP 200 on /api/inspect/executions
3. Both scripts print SERVER_READY when the server is responsive
4. Both scripts shut down cleanly when killed (no orphan processes)
5. Both scripts accept --example and --port arguments
</verification>

<success_criteria>
- start-ui-server.ts starts the graph editor server and health-checks until ready for any of the 5 examples
- start-inspect-server.ts starts the mock inspect server with fixture data and health-checks until ready
- Both print SERVER_READY on success and SERVER_STOPPED on clean shutdown
- Both handle errors gracefully (timeout, missing files, unexpected exits)
</success_criteria>

<output>
After completion, create `.planning/phases/22-mock-fixtures-and-server-automation/22-02-SUMMARY.md`
</output>
