---
phase: 19-build-and-deploy
plan: 02
type: execute
wave: 2
depends_on: [19-01]
files_modified:
  - tutorials/04-deploy-to-aws.md
autonomous: true
requirements:
  - DEPLOY-02

must_haves:
  truths:
    - "User can run rsf deploy on a generated workflow and have a live Lambda Durable Function deployed in their AWS account"
    - "User understands the 6 generated Terraform files and the end-to-end deploy pipeline (codegen, terraform init, terraform apply)"
    - "User can verify the deployment succeeded by checking the Terraform output and the Lambda function in the AWS console"
  artifacts:
    - path: "tutorials/04-deploy-to-aws.md"
      provides: "Step-by-step rsf deploy tutorial with Terraform walkthrough and AWS verification"
      min_lines: 250
  key_links:
    - from: "tutorials/04-deploy-to-aws.md"
      to: "src/rsf/cli/deploy_cmd.py"
      via: "Documents the exact behavior of rsf deploy"
      pattern: "rsf deploy"
    - from: "tutorials/04-deploy-to-aws.md"
      to: "src/rsf/terraform/generator.py"
      via: "Documents the 6 generated Terraform files"
      pattern: "main.tf"
---

<objective>
Create a comprehensive step-by-step tutorial for `rsf deploy` that walks users through deploying a workflow to real AWS infrastructure using Terraform.

Purpose: Users need a hands-on guide to deploy their generated RSF workflow to AWS, understand the generated Terraform module (6 files), see the full deploy pipeline in action (codegen + terraform init + terraform apply), and verify the deployment succeeded.
Output: `tutorials/04-deploy-to-aws.md` — a complete tutorial document.
</objective>

<execution_context>
@/home/esa/.claude/get-shit-done/workflows/execute-plan.md
@/home/esa/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-build-and-deploy/19-01-SUMMARY.md

@src/rsf/cli/deploy_cmd.py
@src/rsf/terraform/generator.py
@src/rsf/terraform/templates/main.tf.j2
@src/rsf/terraform/templates/variables.tf.j2
@src/rsf/terraform/templates/iam.tf.j2
@src/rsf/terraform/templates/outputs.tf.j2
@src/rsf/terraform/templates/cloudwatch.tf.j2
@src/rsf/terraform/templates/backend.tf.j2
@tutorials/01-project-setup.md
@tutorials/02-workflow-validation.md

<interfaces>
<!-- The rsf deploy command behavior (from src/rsf/cli/deploy_cmd.py):

  Arguments:
    workflow: Path to workflow YAML file (default: "workflow.yaml")

  Options:
    --code-only: Re-package and update Lambda code only (default: False)
    --auto-approve / -y: Skip Terraform confirmation prompt (default: False)
    --tf-dir: Terraform output directory (default: "terraform")

  Full deploy pipeline (_deploy_full):
    1. Check workflow file exists
    2. Load and validate the workflow (structural + semantic)
    3. Generate orchestrator + handlers via codegen
       - Prints: "Code generated: orchestrator.py + N handler(s) (M skipped)"
    4. Derive workflow name from definition.comment or workflow filename
    5. Generate 6 Terraform files in tf_dir:
       - main.tf (Lambda function with durable_config)
       - variables.tf (input variables)
       - iam.tf (IAM role and policy)
       - outputs.tf (function ARN, name, role ARN, log group)
       - cloudwatch.tf (log group with retention)
       - backend.tf (optional S3 remote state)
       - Prints: "Terraform generated: N file(s) in terraform (M skipped)"
    6. Check terraform binary exists
    7. Run terraform init
    8. Run terraform apply (or terraform apply -auto-approve with -y flag)
    9. Prints: "Deploy complete"

  The 6 Terraform files create:
    - aws_lambda_function with durable_config block
    - aws_iam_role + aws_iam_role_policy for Lambda execution
    - aws_cloudwatch_log_group for Lambda logs
    - data.archive_file for zipping the source code
    - Variables for region, name_prefix, timeout, memory, etc.
    - Outputs for function ARN, name, role ARN, log group name
-->
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write the rsf deploy tutorial</name>
  <files>tutorials/04-deploy-to-aws.md</files>
  <action>
Create the file `tutorials/04-deploy-to-aws.md` with the following structure and content:

**Title:** "Tutorial 4: Deploying to AWS with `rsf deploy`"

**Sections to include (in order):**

1. **What You'll Learn** — Brief overview: deploy a generated RSF workflow to AWS using Terraform, understand the generated infrastructure files, and verify the deployment.

2. **Prerequisites** —
   - Completed Tutorials 1-3: have a `my-workflow/` directory with validated `workflow.yaml` and generated code
   - AWS CLI installed and configured with credentials (must have permissions to create Lambda functions, IAM roles, CloudWatch log groups)
   - Terraform CLI installed (version 1.0+)
   - An AWS account with the us-east-2 region enabled

   Show verification commands:
   ```bash
   aws sts get-caller-identity
   terraform --version
   ```

3. **Step 1: Prepare the Workflow** — The user should have the order processing workflow from Tutorial 3 in `workflow.yaml` with customized handlers. If not, provide the exact workflow and handler content to copy-paste. This ensures every reader starts from the same point.

4. **Step 2: Deploy** — Show the exact command: `rsf deploy --auto-approve`. Explain: `rsf deploy` does three things in sequence — generates code, generates Terraform files, and runs Terraform. The `--auto-approve` flag skips the interactive Terraform confirmation.

   Show expected output (simplified, realistic):
   ```
   Code generated: orchestrator.py + 3 handler(s) (0 skipped)
   Terraform generated: 6 file(s) in terraform (0 skipped)

   Running terraform init...
   Initializing the backend...
   ...
   Terraform has been successfully initialized!

   Running terraform apply...
   ...
   Apply complete! Resources: 4 added, 0 changed, 0 destroyed.

   Deploy complete
   ```

5. **Step 3: Explore the Generated Terraform** — Show the directory tree with the `terraform/` subdirectory added. Then walk through each of the 6 generated files with a brief explanation:

   a. **terraform/main.tf** — The Lambda function resource with `durable_config` block. Explain:
      - `data.archive_file.lambda_zip` zips the source directory for deployment
      - `aws_lambda_function` creates the Lambda with the durable execution runtime
      - The `durable_config` block enables Lambda Durable Functions with execution timeout and retention period
      - The `handler` points to `generated.orchestrator.lambda_handler` — the orchestrator generated by `rsf generate`

   b. **terraform/variables.tf** — Input variables. Explain: region, name prefix, workflow name, timeout, memory, source_dir, log retention, execution timeout, retention period. All have sensible defaults.

   c. **terraform/iam.tf** — IAM role and policy. Explain the 3 policy statements:
      - CloudWatch Logs — create log groups/streams, put events
      - Lambda self-invoke — for durable execution callbacks
      - Durable execution — checkpoint, get, list operations

   d. **terraform/outputs.tf** — Terraform outputs: function ARN, function name, role ARN, log group name. These are printed after `terraform apply` and can be referenced in other Terraform modules.

   e. **terraform/cloudwatch.tf** — CloudWatch log group with configurable retention (default 14 days).

   f. **terraform/backend.tf** — Optional S3 remote state backend. By default, Terraform stores state locally. For team workflows, configure S3 backend.

   For each file, show the content in an HCL fenced code block, using the actual template output for the order processing workflow (workflow_name="Order processing workflow", resource_id="order_processing_workflow").

6. **Step 4: Verify the Deployment** — Show how to verify using the AWS CLI:
   ```bash
   aws lambda get-function --function-name rsf-Order-processing-workflow --region us-east-2 --query 'Configuration.{FunctionName:FunctionName,Runtime:Runtime,Handler:Handler,State:State}'
   ```
   Expected output showing the function exists with the correct runtime and handler.

   Also mention: check the Terraform outputs with `terraform -chdir=terraform output`.

7. **What's Next** — Point to Tutorial 5 (iterating and invoking) for the --code-only fast path, invoking the deployed Lambda, and tearing down infrastructure. Reinforce: the infrastructure is now live and costing money — Tutorial 5 shows how to tear it down.

**Style guidelines (follow exactly):**
- Follow the established tutorial patterns from Tutorials 1-3
- Use clear, direct language. No marketing fluff.
- Every command should be in a fenced code block with `bash` syntax highlighting.
- Every Terraform file should be in a fenced code block with `hcl` syntax highlighting.
- Use blockquotes (> ) for important notes or tips, especially for cost warnings.
- Keep Terraform file explanations concise — focus on what each file does and why, not every line.
- Do NOT use emojis.
- Reference the actual CLI output format from `deploy_cmd.py` (Rich markup-free representation).
- Use us-east-2 as the AWS region throughout (per project tutorial conventions).
  </action>
  <verify>
    <automated>test -f tutorials/04-deploy-to-aws.md && wc -l tutorials/04-deploy-to-aws.md | awk '{if ($1 >= 250) print "PASS: "$1" lines"; else print "FAIL: only "$1" lines"}'</automated>
  </verify>
  <done>
    - tutorials/04-deploy-to-aws.md exists with 250+ lines
    - Tutorial covers: prerequisites (AWS CLI + Terraform), preparing the workflow, running rsf deploy --auto-approve, exploring all 6 generated Terraform files (main.tf, variables.tf, iam.tf, outputs.tf, cloudwatch.tf, backend.tf), verifying deployment via AWS CLI
    - Each Terraform file explained with actual content for the order processing workflow
    - IAM policy explains all 3 statements (CloudWatch Logs, Lambda self-invoke, Durable execution)
    - AWS region is us-east-2 throughout
    - Cost warning included (infrastructure is live)
    - Pointer to Tutorial 5 for --code-only, invoke, and teardown
  </done>
</task>

</tasks>

<verification>
1. `tutorials/04-deploy-to-aws.md` exists and has 250+ lines
2. Tutorial documents rsf deploy with --auto-approve flag
3. All 6 Terraform files documented (main.tf, variables.tf, iam.tf, outputs.tf, cloudwatch.tf, backend.tf)
4. IAM policy 3-statement structure explained
5. AWS CLI verification command uses us-east-2 region
6. Deploy pipeline explained: codegen + terraform init + terraform apply
7. Cost warning present — infrastructure is live and costing money
</verification>

<success_criteria>
A user reading this tutorial can: run `rsf deploy --auto-approve` to deploy a workflow to AWS, understand all 6 generated Terraform files, and verify the deployment succeeded via AWS CLI.
</success_criteria>

<output>
After completion, create `.planning/phases/19-build-and-deploy/19-02-SUMMARY.md`
</output>
